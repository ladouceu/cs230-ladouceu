{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadc94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f70ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf8d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be >=2.6.2\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5111670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\"frame\":0, \"id\":1, \"x\":2, \"y\":3, \"w\":4, \"h\":5, \"x1\":6, \"x2\":7, \"conf\":9}\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b78d3c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on file: data/test/MOT16-01/det/det.txt\n",
      "[[ 1.0000e+00  1.0000e+00  7.7268e+02  4.5543e+02  4.1871e+01  1.2761e+02\n",
      "   2.1262e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  2.0000e+00  7.1779e+02  4.5129e+02  4.4948e+01  1.3684e+02\n",
      "   1.7969e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  3.0000e+00  2.3074e+02  4.6507e+02  2.1974e+01  6.7922e+01\n",
      "   1.6718e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  4.0000e+00  1.0017e+03  4.5586e+02  6.3980e+01  1.9394e+02\n",
      "   6.3705e-01 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  5.0000e+00  7.0264e+02  3.7421e+02  7.3643e+01  2.2293e+02\n",
      "  -1.0042e-01 -1.0000e+00 -1.0000e+00 -1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "videos = glob.glob(\"data/test/*/det/det.txt\")\n",
    "\n",
    "for video in videos:\n",
    "    print(\"Evaluating on file: {}\".format(file))\n",
    "    data_video = np.loadtxt(file, delimiter=\",\")\n",
    "    frames = np.unique(data[:,header[\"frame\"]])\n",
    "    # put an id on all objects in the first frame\n",
    "    first_frame = min(frames)\n",
    "    data_first_frame = data_video[data_video[:,header[\"frame\"]]==first_frame,:]\n",
    "    largest_id = len(data_old_frame)\n",
    "    old_objs = # all objs from first frame in a tensor\n",
    "    old_id_map = list(range(1,largest_id+1)) # map from position in tensor above to id of object\n",
    "    data_first_frame[:,header[\"id\"]] = old_id_map\n",
    "    \n",
    "    # iterate through frames, on each next frame find the best match from\n",
    "    # the objects of the previous match and remember the matching score. \n",
    "    # The matching score must be larger than a certain threshold. Not \n",
    "    # more than 1 objects in the next frame can be matched to one object in the\n",
    "    # previous frame, so recursively go through all unmatched objects until they\n",
    "    # are all matched. If no match is found for an object, assigned a new id \n",
    "    # being largest_id + 1 \n",
    "    for frame in frames:\n",
    "        data_new_frame = data_video[data_video[:,header[\"frame\"]]==frame,:]\n",
    "        new_objs = # all objs from this new frame in a tensor\n",
    "        new_id_map = [] # map from position in tensor above to id of object\n",
    "        for r,det in enumerate(data_new_frame):\n",
    "            new_obj = # a tensor of all same pictures with same dim as old_obj\n",
    "            similarities = compute_similarity(new_obj, old_obj)\n",
    "            i = np.argmax(similarities)\n",
    "            score = similarities[i]\n",
    "            if score > thresh:\n",
    "                new_id_map += [old_id_map[i]]\n",
    "            else:\n",
    "                largest_id += 1\n",
    "                new_id_map += [largest_id]\n",
    "        \n",
    "        data_new_frame[:,header[\"id\"]] = new_id_map\n",
    "        \n",
    "        #update old variables\n",
    "        old_objs = new_objs\n",
    "        old_id_map = new_id_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ec09e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000e+00, -1.0000e+00,  7.7268e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 1.0000e+00, -1.0000e+00,  7.1779e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 1.0000e+00, -1.0000e+00,  2.3074e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       ...,\n",
       "       [ 4.5000e+02, -1.0000e+00,  1.7248e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 4.5000e+02, -1.0000e+00,  2.8900e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 4.5000e+02, -1.0000e+00,  1.6055e+03, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(files[0],delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df51421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data[0:1,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b93ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de969323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e452f005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "        23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "        34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "        45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "        56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "        67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "        78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "        89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "       100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "       111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "       122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "       133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "       144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154.,\n",
       "       155., 156., 157., 158., 159., 160., 161., 162., 163., 164., 165.,\n",
       "       166., 167., 168., 169., 170., 171., 172., 173., 174., 175., 176.,\n",
       "       177., 178., 179., 180., 181., 182., 183., 184., 185., 186., 187.,\n",
       "       188., 189., 190., 191., 192., 193., 194., 195., 196., 197., 198.,\n",
       "       199., 200., 201., 202., 203., 204., 205., 206., 207., 208., 209.,\n",
       "       210., 211., 212., 213., 214., 215., 216., 217., 218., 219., 220.,\n",
       "       221., 222., 223., 224., 225., 226., 227., 228., 229., 230., 231.,\n",
       "       232., 233., 234., 235., 236., 237., 238., 239., 240., 241., 242.,\n",
       "       243., 244., 245., 246., 247., 248., 249., 250., 251., 252., 253.,\n",
       "       254., 255., 256., 257., 258., 259., 260., 261., 262., 263., 264.,\n",
       "       265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
       "       276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286.,\n",
       "       287., 288., 289., 290., 291., 292., 293., 294., 295., 296., 297.,\n",
       "       298., 299., 300., 301., 302., 303., 304., 305., 306., 307., 308.,\n",
       "       309., 310., 311., 312., 313., 314., 315., 316., 317., 318., 319.,\n",
       "       320., 321., 322., 323., 324., 325., 326., 327., 328., 329., 330.,\n",
       "       331., 332., 333., 334., 335., 336., 337., 338., 339., 340., 341.,\n",
       "       342., 343., 344., 345., 346., 347., 348., 349., 350., 351., 352.,\n",
       "       353., 354., 355., 356., 357., 358., 359., 360., 361., 362., 363.,\n",
       "       364., 365., 366., 367., 368., 369., 370., 371., 372., 373., 374.,\n",
       "       375., 376., 377., 378., 379., 380., 381., 382., 383., 384., 385.,\n",
       "       386., 387., 388., 389., 390., 391., 392., 393., 394., 395., 396.,\n",
       "       397., 398., 399., 400., 401., 402., 403., 404., 405., 406., 407.,\n",
       "       408., 409., 410., 411., 412., 413., 414., 415., 416., 417., 418.,\n",
       "       419., 420., 421., 422., 423., 424., 425., 426., 427., 428., 429.,\n",
       "       430., 431., 432., 433., 434., 435., 436., 437., 438., 439., 440.,\n",
       "       441., 442., 443., 444., 445., 446., 447., 448., 449., 450.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = np.unique(data[:,header[\"frame\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef52549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
