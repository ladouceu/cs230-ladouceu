{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "produce_test_tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akHkEVoO1ikX"
      },
      "source": [
        "## Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQy6VsfH1iKl"
      },
      "source": [
        "target_shape = (200,200)\n",
        "batch_size = 2**9 # 2**9 is the max for colab pro with high ram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYkDOL--yidR"
      },
      "source": [
        "## Define the siamese model\n",
        "(same definition as that in the training notebook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lyf-xgvyhj7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import resnet\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "class DistanceLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    This layer is responsible for computing the distance between the anchor\n",
        "    embedding and the positive embedding, and the anchor embedding and the\n",
        "    negative embedding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, anchor, positive, negative):\n",
        "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "        return (ap_distance, an_distance)\n",
        "\n",
        "class SiameseModel(Model):\n",
        "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
        "\n",
        "    Computes the triplet loss using the three embeddings produced by the\n",
        "    Siamese Network.\n",
        "\n",
        "    The triplet loss is defined as:\n",
        "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding, margin=0.5):\n",
        "        super(SiameseModel, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "\n",
        "        # the embedding model\n",
        "        if embedding is None:\n",
        "          base_cnn = resnet.ResNet50(\n",
        "              weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
        "          )\n",
        "          location_input = layers.Input(shape=(4,))\n",
        "\n",
        "          flatten = layers.Flatten()(base_cnn.output)\n",
        "          dense1 = layers.Dense(256, activation=\"relu\")(flatten) # TODO: made it simpler by going from 512 to 256\n",
        "          dense1 = layers.BatchNormalization()(dense1)\n",
        "          concat = layers.Concatenate()([dense1, location_input])\n",
        "          dense2 = layers.Dense(128, activation=\"relu\")(concat) # TODO: made it simpler by going from 256 to 128\n",
        "          dense2 = layers.BatchNormalization()(dense2)\n",
        "          output = layers.Dense(128)(dense2)# TODO: made it simpler by going from 256 to 128\n",
        "\n",
        "          # train only the last layers of the resnet (when set to conv5_block3_out,\n",
        "          # none is trainable)\n",
        "          trainable = False\n",
        "          for layer in base_cnn.layers:\n",
        "              if layer.name == \"conv5_block3_out\": \n",
        "                  trainable = True\n",
        "              layer.trainable = trainable\n",
        "\n",
        "          self.embedding = Model([base_cnn.input,location_input], output, name=\"Embedding\")\n",
        "        else: # if embedding is passed as arg\n",
        "          self.embedding = embedding\n",
        "\n",
        "        # the siamese network model \n",
        "        anchor_input_image = layers.Input(name=\"anchor_image\", shape=target_shape + (3,))\n",
        "        positive_input_image = layers.Input(name=\"positive_image\", shape=target_shape + (3,))\n",
        "        negative_input_image = layers.Input(name=\"negative_image\", shape=target_shape + (3,))\n",
        "\n",
        "        anchor_input_location = layers.Input(name=\"anchor_location\",shape=(4,))\n",
        "        positive_input_location = layers.Input(name=\"positive_location\",shape=(4,))\n",
        "        negative_input_location = layers.Input(name=\"negative_location\",shape=(4,))\n",
        "\n",
        "        distances = DistanceLayer()(\n",
        "            self.embedding((resnet.preprocess_input(anchor_input_image), anchor_input_location)),\n",
        "            self.embedding((resnet.preprocess_input(positive_input_image), positive_input_location)),\n",
        "            self.embedding((resnet.preprocess_input(negative_input_image), negative_input_location)),\n",
        "        )\n",
        "\n",
        "        siamese_network = Model(\n",
        "            inputs=[(anchor_input_image,   anchor_input_location),\n",
        "                    (positive_input_image, positive_input_location), \n",
        "                    (negative_input_image, negative_input_location)],\n",
        "            outputs=distances\n",
        "        )\n",
        "        self.siamese_network = siamese_network\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.siamese_network(inputs)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # GradientTape is a context manager that records every operation that\n",
        "        # you do inside. We are using it here to compute the loss so we can get\n",
        "        # the gradients and apply them using the optimizer specified in\n",
        "        # `compile()`.\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self._compute_loss(data)\n",
        "\n",
        "        # Storing the gradients of the loss function with respect to the\n",
        "        # weights/parameters.\n",
        "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
        "\n",
        "        # Applying the gradients on the model using the specified optimizer\n",
        "        self.optimizer.apply_gradients(\n",
        "            zip(gradients, self.siamese_network.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Let's update and return the training loss metric.\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        loss = self._compute_loss(data)\n",
        "\n",
        "        # Let's update and return the loss metric.\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def _compute_loss(self, data):\n",
        "        # The output of the network is a tuple containing the distances\n",
        "        # between the anchor and the positive example, and the anchor and\n",
        "        # the negative example.\n",
        "        ap_distance, an_distance = self.siamese_network(data)\n",
        "\n",
        "        # Computing the Triplet Loss by subtracting both distances and\n",
        "        # making sure we don't get a negative value.\n",
        "        loss = ap_distance - an_distance\n",
        "        loss = tf.maximum(loss + self.margin, 0.0)\n",
        "        return loss\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We need to list our metrics here so the `reset_states()` can be\n",
        "        # called automatically.\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def save_embedding(self, path):\n",
        "      self.embedding.save(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZcicXTXp2M_",
        "outputId": "51d16e85-c6e9-4f27-f7c9-40f76294ca30"
      },
      "source": [
        "# load the model\n",
        "embedding = load_model(\"drive/MyDrive/cs230-models/training_1/models_epoch_9_trainloss_0.0005582810845226049_valloss_0.0681820660829544\")\n",
        "siamese_model = SiameseModel(embedding)\n",
        "siamese_model.compile(optimizer=optimizers.Adam(0.0001))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydGjNBaA1thk"
      },
      "source": [
        "## Define the test input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEoimBKEpuou"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Same as the one defined above\n",
        "def get_object_location(row, image):\n",
        "    id_, x, y, w, h = row\n",
        "    abs_loc = np.array([float(x),float(y),float(w),float(h)])\n",
        "    image_height,image_width = image.shape[0],image.shape[1]\n",
        "    id_ = int(id_)\n",
        "    x = int(max(x,0))\n",
        "    y = int(max(y,0))\n",
        "    w = int(min(w,image_width-x))\n",
        "    h = int(min(h,image_height-y))\n",
        "    obj = image[y:y+h,x:x+w]\n",
        "    obj = cv2.resize(obj, dsize=target_shape)#, interpolation=cv2.INTER_CUBIC) #TODO : should I keep this interpolation?\n",
        "    obj = obj.astype(np.float32)\n",
        "    obj /= 255.\n",
        "    return obj,np.array([x/image_width,y/image_height,w/image_width,h/image_height]), abs_loc # return object image and relative location and abs loc\n",
        "\n",
        "def test_gen():\n",
        "    # det file header\n",
        "    header = {\"frame\":0, \"id\":1, \"bb_left\":2, \"bb_top\":3, \"bb_width\":4, \"bb_height\":5, \"conf\":6, \"x\":7, \"y\":8, \"z\":9}\n",
        "\n",
        "    # get the list of det files\n",
        "    det_files = sorted(glob.glob(\"drive/MyDrive/cs230-data/test/*/*/det.txt\"))\n",
        "\n",
        "    for det_file in det_files:\n",
        "        video = int(det_file.split(os.sep)[-3][-2:])\n",
        "        det = np.loadtxt(det_file,delimiter=\",\")\n",
        "        frames = np.sort(np.unique(det[:,header[\"frame\"]]))\n",
        "        for frame in frames:\n",
        "            image_file = os.path.join(os.sep.join(det_file.split(os.sep)[:-2]),\"img1/{:06d}.jpg\".format(int(frame)))\n",
        "            image = cv2.imread(image_file)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            det_frame = det[det[:,header[\"frame\"]] == frame]\n",
        "            image_frame_batch = []\n",
        "            rel_loc_frame_batch = []\n",
        "            abs_loc_frame_batch = []\n",
        "            conf_batch = []\n",
        "            for row in det_frame:\n",
        "                obj_image, obj_rel_loc, obj_abs_loc = get_object_location(row[1:6], image)\n",
        "                image_frame_batch.append(obj_image)\n",
        "                rel_loc_frame_batch.append(obj_rel_loc)\n",
        "                abs_loc_frame_batch.append(obj_abs_loc)\n",
        "                conf_batch.append(row[header[\"conf\"]:header[\"conf\"]+1])\n",
        "            yield np.array(image_frame_batch),np.array(rel_loc_frame_batch), video, int(frame), np.array(abs_loc_frame_batch), np.array(conf_batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gfYASXl2rUI"
      },
      "source": [
        "## Run the embedding over all detected images in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz99vG6Jpumg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb0eb90-b75e-4091-a3cd-a8754f3a612e"
      },
      "source": [
        "# process all object images with the embedding\n",
        "for i,data in enumerate(test_gen()):\n",
        "  image, rel_loc, video, frame, abs_loc, conf = data\n",
        "  if i % 100 == 0:\n",
        "    print(\"{} frames were processed.\".format(i))\n",
        "    print(\"We are at video {}, and frame {}\\n--------------------------\".format(video,frame))\n",
        "  test_preds = siamese_model.embedding.predict_on_batch([image, rel_loc])\n",
        "  num_preds = test_preds.shape[0]\n",
        "  ones = np.ones((num_preds,1))\n",
        "  frame_col = frame*ones\n",
        "  na_col = -1 * ones\n",
        "  test_preds = np.hstack((frame_col, na_col, abs_loc, conf, na_col, na_col, na_col, test_preds))\n",
        "  save_path = \"drive/MyDrive/cs230-preds/training_1/preds_{:02d}_{:06d}.txt\".format(video, frame)\n",
        "  np.savetxt(save_path, test_preds, delimiter=',')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 frames were processed.\n",
            "We are at video 1, and frame 1\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at video 1, and frame 101\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at video 1, and frame 201\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at video 1, and frame 301\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at video 1, and frame 401\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at video 3, and frame 51\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at video 3, and frame 151\n",
            "--------------------------\n",
            "700 frames were processed.\n",
            "We are at video 3, and frame 251\n",
            "--------------------------\n",
            "800 frames were processed.\n",
            "We are at video 3, and frame 351\n",
            "--------------------------\n",
            "900 frames were processed.\n",
            "We are at video 3, and frame 451\n",
            "--------------------------\n",
            "1000 frames were processed.\n",
            "We are at video 3, and frame 551\n",
            "--------------------------\n",
            "1100 frames were processed.\n",
            "We are at video 3, and frame 651\n",
            "--------------------------\n",
            "1200 frames were processed.\n",
            "We are at video 3, and frame 751\n",
            "--------------------------\n",
            "1300 frames were processed.\n",
            "We are at video 3, and frame 851\n",
            "--------------------------\n",
            "1400 frames were processed.\n",
            "We are at video 3, and frame 951\n",
            "--------------------------\n",
            "1500 frames were processed.\n",
            "We are at video 3, and frame 1051\n",
            "--------------------------\n",
            "1600 frames were processed.\n",
            "We are at video 3, and frame 1151\n",
            "--------------------------\n",
            "1700 frames were processed.\n",
            "We are at video 3, and frame 1251\n",
            "--------------------------\n",
            "1800 frames were processed.\n",
            "We are at video 3, and frame 1351\n",
            "--------------------------\n",
            "1900 frames were processed.\n",
            "We are at video 3, and frame 1451\n",
            "--------------------------\n",
            "2000 frames were processed.\n",
            "We are at video 6, and frame 51\n",
            "--------------------------\n",
            "2100 frames were processed.\n",
            "We are at video 6, and frame 151\n",
            "--------------------------\n",
            "2200 frames were processed.\n",
            "We are at video 6, and frame 251\n",
            "--------------------------\n",
            "2300 frames were processed.\n",
            "We are at video 6, and frame 351\n",
            "--------------------------\n",
            "2400 frames were processed.\n",
            "We are at video 6, and frame 451\n",
            "--------------------------\n",
            "2500 frames were processed.\n",
            "We are at video 6, and frame 551\n",
            "--------------------------\n",
            "2600 frames were processed.\n",
            "We are at video 6, and frame 651\n",
            "--------------------------\n",
            "2700 frames were processed.\n",
            "We are at video 6, and frame 751\n",
            "--------------------------\n",
            "2800 frames were processed.\n",
            "We are at video 6, and frame 851\n",
            "--------------------------\n",
            "2900 frames were processed.\n",
            "We are at video 6, and frame 951\n",
            "--------------------------\n",
            "3000 frames were processed.\n",
            "We are at video 6, and frame 1051\n",
            "--------------------------\n",
            "3100 frames were processed.\n",
            "We are at video 6, and frame 1151\n",
            "--------------------------\n",
            "3200 frames were processed.\n",
            "We are at video 7, and frame 57\n",
            "--------------------------\n",
            "3300 frames were processed.\n",
            "We are at video 7, and frame 157\n",
            "--------------------------\n",
            "3400 frames were processed.\n",
            "We are at video 7, and frame 257\n",
            "--------------------------\n",
            "3500 frames were processed.\n",
            "We are at video 7, and frame 357\n",
            "--------------------------\n",
            "3600 frames were processed.\n",
            "We are at video 7, and frame 457\n",
            "--------------------------\n",
            "3700 frames were processed.\n",
            "We are at video 8, and frame 57\n",
            "--------------------------\n",
            "3800 frames were processed.\n",
            "We are at video 8, and frame 157\n",
            "--------------------------\n",
            "3900 frames were processed.\n",
            "We are at video 8, and frame 257\n",
            "--------------------------\n",
            "4000 frames were processed.\n",
            "We are at video 8, and frame 357\n",
            "--------------------------\n",
            "4100 frames were processed.\n",
            "We are at video 8, and frame 457\n",
            "--------------------------\n",
            "4200 frames were processed.\n",
            "We are at video 8, and frame 557\n",
            "--------------------------\n",
            "4300 frames were processed.\n",
            "We are at video 12, and frame 32\n",
            "--------------------------\n",
            "4400 frames were processed.\n",
            "We are at video 12, and frame 132\n",
            "--------------------------\n",
            "4500 frames were processed.\n",
            "We are at video 12, and frame 232\n",
            "--------------------------\n",
            "4600 frames were processed.\n",
            "We are at video 12, and frame 332\n",
            "--------------------------\n",
            "4700 frames were processed.\n",
            "We are at video 12, and frame 432\n",
            "--------------------------\n",
            "4800 frames were processed.\n",
            "We are at video 12, and frame 544\n",
            "--------------------------\n",
            "4900 frames were processed.\n",
            "We are at video 12, and frame 644\n",
            "--------------------------\n",
            "5000 frames were processed.\n",
            "We are at video 12, and frame 744\n",
            "--------------------------\n",
            "5100 frames were processed.\n",
            "We are at video 12, and frame 844\n",
            "--------------------------\n",
            "5200 frames were processed.\n",
            "We are at video 14, and frame 44\n",
            "--------------------------\n",
            "5300 frames were processed.\n",
            "We are at video 14, and frame 144\n",
            "--------------------------\n",
            "5400 frames were processed.\n",
            "We are at video 14, and frame 244\n",
            "--------------------------\n",
            "5500 frames were processed.\n",
            "We are at video 14, and frame 344\n",
            "--------------------------\n",
            "5600 frames were processed.\n",
            "We are at video 14, and frame 444\n",
            "--------------------------\n",
            "5700 frames were processed.\n",
            "We are at video 14, and frame 544\n",
            "--------------------------\n",
            "5800 frames were processed.\n",
            "We are at video 14, and frame 644\n",
            "--------------------------\n",
            "5900 frames were processed.\n",
            "We are at video 14, and frame 744\n",
            "--------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJoXOAt3KIN"
      },
      "source": [
        "## Produce the test tracking results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "525-LNmcv0j-"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrIw6htIwKOp"
      },
      "source": [
        "header = {\"frame\":0, \"id\":1, \"bb_left\":2, \"bb_top\":3, \"bb_width\":4, \"bb_height\":5, \"conf\":6, \"x\":7, \"y\":8, \"z\":9}\n",
        "threshold = 0.3 # TODO: Adjust that parameter, I should select it using cv with validation set"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqeLx0c18r5z"
      },
      "source": [
        "# videos in the test dir\n",
        "videos = [1,3,6,7,8,12,14]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFcTNjxs6iQT",
        "outputId": "218b9af0-2bf0-4b4a-eb36-67313227f8e1"
      },
      "source": [
        "def find_closest_id(new_embedding, old_embeddings):\n",
        "  ids = old_embeddings[:,header[\"id\"]]\n",
        "  # get the distance between each old embedding and the new embedding\n",
        "  diff = old_embeddings[:,10:] - new_embedding\n",
        "  dist = np.sum(np.square(diff),1)\n",
        "  # print(dist)\n",
        "  # filter the distances and the ids with the threshold for distance\n",
        "  filt = dist < threshold\n",
        "  ids = ids[filt]\n",
        "  dist = dist[filt]\n",
        "  \n",
        "  # return -1 if no old embedding is close enough to the new embedding\n",
        "  if len(ids) == 0:\n",
        "    return -1\n",
        "  # else return the id of the old embedding closest to the new embedding\n",
        "  return ids[np.argmin(dist)]\n",
        "\n",
        "for video in videos:\n",
        "  print(\"Starting to process test files for video \",video,\"\\n------------------------\")\n",
        "  # read all files from this video\n",
        "  files = glob.glob(\"drive/MyDrive/cs230-preds/training_1/preds_{:02d}_*.txt\".format(video))\n",
        "  files.sort()\n",
        "  old_embeddings = np.loadtxt(files[0], delimiter=',')\n",
        "  old_next_id = len(old_embeddings)+1\n",
        "  old_embeddings[:,header[\"id\"]] = range(1,old_next_id)\n",
        "  tracking = old_embeddings[:,:10]\n",
        "  for i,file in enumerate(files[1:]): # important to start at file 1 and not file 0 since we've already read file 0\n",
        "    if i % 100 == 0:\n",
        "      print(\"{} frames were processed.\".format(i))\n",
        "      print(\"We are at file: {}\\n--------------------------\".format(file))\n",
        "    new_embeddings = np.loadtxt(file, delimiter=\",\", ndmin=2)\n",
        "    # match each new embedding with the closest old embedding that is close enough (below thresh)\n",
        "    new_embeddings[:,header[\"id\"]] = np.apply_along_axis(lambda x: find_closest_id(x, old_embeddings), 1, new_embeddings[:,10:])\n",
        "    # if no match is found, assign new ids\n",
        "    filt = new_embeddings[:,header[\"id\"]]==-1\n",
        "    new_next_id = old_next_id + np.sum(filt)\n",
        "    if old_next_id != new_next_id:\n",
        "      # print(i,old_next_id,new_next_id) #uncomment for debugging\n",
        "      new_embeddings[filt, header[\"id\"]] = range(old_next_id, new_next_id) \n",
        "    tracking = np.vstack((tracking,new_embeddings[:,:10]))\n",
        "    old_embeddings = new_embeddings\n",
        "    old_next_id = new_next_id\n",
        "    # if i > 5:\n",
        "    #   sys.exit()\n",
        "  # save to file\n",
        "  save_path = \"drive/MyDrive/cs230-tracking/training_1/tracking_{:02d}.txt\".format(video,video)\n",
        "  tracking = pd.DataFrame(tracking, columns = header.keys())\n",
        "  tracking[\"frame\"] = tracking[\"frame\"].astype(int)\n",
        "  tracking[\"id\"] = tracking[\"id\"].astype(int)\n",
        "  tracking[\"x\"] = tracking[\"x\"].astype(int)\n",
        "  tracking[\"y\"] = tracking[\"y\"].astype(int)\n",
        "  tracking[\"z\"] = tracking[\"z\"].astype(int)\n",
        "  tracking.to_csv(save_path, index=False, header=False)\n",
        "  # np.savetxt(save_path, tracking, delimiter=',', fmt = ['%s','%s','%10.5f','%10.5f','%10.5f','%10.5f','%10.5f','%s','%s','%s'])\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to process test files for video  1 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_01_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_01_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_01_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_01_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_01_000402.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  3 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000402.txt\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000502.txt\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000602.txt\n",
            "--------------------------\n",
            "700 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000702.txt\n",
            "--------------------------\n",
            "800 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000802.txt\n",
            "--------------------------\n",
            "900 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_000902.txt\n",
            "--------------------------\n",
            "1000 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_001002.txt\n",
            "--------------------------\n",
            "1100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_001102.txt\n",
            "--------------------------\n",
            "1200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_001202.txt\n",
            "--------------------------\n",
            "1300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_001302.txt\n",
            "--------------------------\n",
            "1400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_03_001402.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  6 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000402.txt\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000502.txt\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000602.txt\n",
            "--------------------------\n",
            "700 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000702.txt\n",
            "--------------------------\n",
            "800 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000802.txt\n",
            "--------------------------\n",
            "900 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_000902.txt\n",
            "--------------------------\n",
            "1000 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_001002.txt\n",
            "--------------------------\n",
            "1100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_06_001102.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  7 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_07_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_07_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_07_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_07_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_07_000402.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  8 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000402.txt\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000502.txt\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_08_000602.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  12 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000402.txt\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000514.txt\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000614.txt\n",
            "--------------------------\n",
            "700 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000714.txt\n",
            "--------------------------\n",
            "800 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_12_000814.txt\n",
            "--------------------------\n",
            "Starting to process test files for video  14 \n",
            "------------------------\n",
            "0 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000002.txt\n",
            "--------------------------\n",
            "100 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000102.txt\n",
            "--------------------------\n",
            "200 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000202.txt\n",
            "--------------------------\n",
            "300 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000302.txt\n",
            "--------------------------\n",
            "400 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000402.txt\n",
            "--------------------------\n",
            "500 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000502.txt\n",
            "--------------------------\n",
            "600 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000602.txt\n",
            "--------------------------\n",
            "700 frames were processed.\n",
            "We are at file: drive/MyDrive/cs230-preds/training_1/preds_14_000702.txt\n",
            "--------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_fVkpux1GUs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}