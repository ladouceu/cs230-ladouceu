{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52dc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d12a59",
   "metadata": {},
   "source": [
    "# develop the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19225b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename, coords):\n",
    "    # source: https://keras.io/examples/vision/siamese_network/\n",
    "    target_shape = (200,200)\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    x = tf.math.maximum(tf.cast(coords[0], tf.int32),0)\n",
    "    y = tf.math.maximum(tf.cast(coords[1], tf.int32),0)\n",
    "    w = tf.math.minimum(tf.cast(coords[2], tf.int32),tf.subtract(tf.shape(image)[1],x))\n",
    "    h = tf.math.minimum(tf.cast(coords[3], tf.int32),tf.subtract(tf.shape(image)[0],y))\n",
    "    image = tf.slice(image, [y,x,0], [h,w,-1] )\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_csv(line, video):\n",
    "    record_defaults = [-1.]*9\n",
    "    parsed_line = tf.io.decode_csv(line, record_defaults)\n",
    "    features = tf.stack(tf.concat((parsed_line,[video]),0))  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    return features\n",
    "\n",
    "def get_filename(video, frame):\n",
    "    # preprocess tensors\n",
    "    frame = tf.strings.as_string(tf.cast(frame, tf.int32))\n",
    "    video = tf.strings.as_string(tf.cast(video, tf.int32))\n",
    "    # get the leading zeros\n",
    "    num_zeros_frame = tf.subtract(6,tf.strings.length(frame))\n",
    "    leading_zeros_frame = tf.repeat(\"0\",num_zeros_frame,0)\n",
    "    leading_zeros_frame = tf.strings.reduce_join(leading_zeros_frame)\n",
    "    num_zeros_video = tf.subtract(2,tf.strings.length(video))\n",
    "    leading_zeros_video = tf.repeat(\"0\",num_zeros_video,0)\n",
    "    leading_zeros_video = tf.strings.reduce_join(leading_zeros_video)    \n",
    "    # get the filename\n",
    "    filename = tf.add(\"data/train/MOT16-\", leading_zeros_video)\n",
    "    filename = tf.add(filename, video)\n",
    "    filename = tf.add(filename,\"/img1/\")\n",
    "    filename = tf.add(filename, leading_zeros_frame)\n",
    "    filename = tf.add(filename, frame)\n",
    "    filename = tf.add(filename, \".jpg\")\n",
    "#     for i in filename:\n",
    "#         print(i)\n",
    "    return filename\n",
    "\n",
    "def get_object(gt_line):\n",
    "    frame = gt_line[0]\n",
    "    id_ = gt_line[1]\n",
    "    video = gt_line[-1]\n",
    "    coords = gt_line[2:6]\n",
    "    \n",
    "#     video = 2\n",
    "    filename = get_filename(video, frame)\n",
    "    image = preprocess_image(filename, coords)\n",
    "#     return image,tf.cast(video,tf.int32),tf.cast(frame,tf.int32),tf.cast(id_,tf.int32)\n",
    "    return image,video,frame,id_\n",
    "\n",
    "def read_gt(filename):\n",
    "    video = tf.strings.split(filename,os.sep)[2]\n",
    "    video = tf.strings.substr(video, 6, 2)\n",
    "    video = tf.strings.to_number(video, tf.float32)\n",
    "    gt = tf.data.TextLineDataset(filename).map(lambda x: decode_csv(x,video))\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices([\"data/train/MOT16-02/gt/gt.txt\",\"data/train/MOT16-04/gt/gt.txt\"])\n",
    "train_filepaths = glob.glob(\"data/train/*/gt/gt.txt\")\n",
    "valid_filepaths = glob.glob(\"data/train/*/gt/gt.txt\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_filepaths)\n",
    "dataset = dataset.flat_map(read_gt)\n",
    "anchor = dataset.map(get_object)\n",
    "# dataset = dataset.batch(2)\n",
    "\n",
    "for i,anchor in enumerate(anchor.skip(100).take(10)):\n",
    "    print(\"Image \",i)\n",
    "    positive_dataset = dataset.filter(lambda x: (anchor[1]==x[-1]) and (anchor[2]!=x[0]) and (anchor[3]==x[1])) # same video, diff frame, same id_\n",
    "#     positive_dataset = tf.data.experimental.sample_from_datasets([positive_dataset])\n",
    "    positive_dataset.shuffle(100)\n",
    "    positive_dataset = positive_dataset.take(1)\n",
    "    positive = positive_dataset.map(get_object)\n",
    "    negative_dataset = dataset.filter(lambda x: not ((anchor[1]==x[-1]) and (anchor[3]==x[1]))) # not (same video and same id_)\n",
    "#     negative_dataset = tf.data.experimental.sample_from_datasets([negative_dataset])\n",
    "    negative_dataset = negative_dataset.shuffle(100)\n",
    "    negative_dataset = negative_dataset.take(1)\n",
    "    negative = negative_dataset.map(get_object)\n",
    "    print(\"anchor\")\n",
    "    plt.imshow(anchor[0])\n",
    "    plt.show()\n",
    "    print(\"positive\")\n",
    "    plt.imshow(positive.__iter__().__next__()[0])\n",
    "    plt.show()\n",
    "    print(\"negative\")\n",
    "    plt.imshow(negative.__iter__().__next__()[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c29c3",
   "metadata": {},
   "source": [
    "# make the input pipeline as a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0157883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_gen(stop):\n",
    "    train_filepaths = glob.glob(\"data/train/*/gt/gt.txt\")\n",
    "    valid_filepaths = glob.glob(\"data/train/*/gt/gt.txt\")\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_filepaths)\n",
    "    dataset = dataset.flat_map(read_gt)\n",
    "    anchors = dataset.map(get_object)\n",
    "    i = 0\n",
    "    for anchor in anchors: \n",
    "        if(i>=stop): break\n",
    "        positive_dataset = dataset.filter(lambda x: (anchor[1]==x[-1]) and (anchor[2]!=x[0]) and (anchor[3]==x[1])) # same video, diff frame, same id_\n",
    "        positive_dataset.shuffle(100)\n",
    "        positive_dataset = positive_dataset.take(1)\n",
    "        positive = positive_dataset.map(get_object)\n",
    "        negative_dataset = dataset.filter(lambda x: not ((anchor[1]==x[-1]) and (anchor[3]==x[1]))) # not (same video and same id_)\n",
    "        negative_dataset = negative_dataset.shuffle(100)\n",
    "        negative_dataset = negative_dataset.take(1)\n",
    "        negative = negative_dataset.map(get_object)\n",
    "        yield anchor[0],positive.__iter__().__next__()[0],negative.__iter__().__next__()[0]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# TODO: If this dataset is too slow, I could simply make the positive and negative datasets this way\n",
    "# the positive is just the anchor + 1, and the negative is the anchors shuffled \n",
    "triplet_dataset = tf.data.Dataset.from_generator(triplet_gen, args=[100], output_types=tf.float32, output_shapes = (3, 200, 200, 3) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01403268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([ 10   3 200 200   3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "triplet_dataset = triplet_dataset.batch(10)\n",
    "for i in triplet_dataset:\n",
    "    print(tf.shape(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b4ce2",
   "metadata": {},
   "source": [
    "# other codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "a863c68e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-675-1de10c716019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_to_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdataset5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdataset5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextLineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "#source: https://stackoverflow.com/questions/49525056/tensorflow-python-reading-2-files/49548224#49548224\n",
    "\n",
    "feature_names = ['f1','f2','f3','f4','f5']\n",
    "record_defaults = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "\n",
    "\n",
    "def decode_csv(line):\n",
    "    parsed_line = tf.decode_csv(line, record_defaults)\n",
    "    label =  parsed_line[-1]      # label is the last element of the list\n",
    "    del parsed_line[-1]           # delete the last element from the list\n",
    "    del parsed_line[0]            # even delete the first element bcz it is assumed NOT to be a feature\n",
    "    features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    #label = tf.stack(label)          #NOT needed. Only if more than 1 column makes the label...\n",
    "    batch_to_return = features, label\n",
    "    return batch_to_return\n",
    "\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset5 = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "dataset5 = dataset5.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "dataset5 = dataset5.shuffle(buffer_size=1000)\n",
    "dataset5 = dataset5.batch(7)\n",
    "iterator5 = dataset5.make_initializable_iterator()\n",
    "next_element5 = iterator5.get_next()\n",
    "\n",
    "# Initialize `iterator` with training data. \n",
    "training_filenames = [\"train_data1.csv\", #TODO: I know wwhich ones\n",
    "                      \"train_data2.csv\"]\n",
    "\n",
    "# Initialize `iterator` with validation data.\n",
    "validation_filenames = [\"dev_data1.csv\"] #TODO: I know w=which ones\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train 2 epochs. Then validate train set. Then validate dev set.\n",
    "    for _ in range(2):     \n",
    "        sess.run(iterator5.initializer, feed_dict={filenames: training_filenames})\n",
    "        while True:\n",
    "            try:\n",
    "                features, labels = sess.run(next_element5)\n",
    "                # Train...\n",
    "                print(\"(train) features: \")\n",
    "                print(features)\n",
    "                print(\"(train) labels: \")\n",
    "                print(labels)  \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Out of range error triggered (looped through training set 1 time)\")\n",
    "                break\n",
    "\n",
    "    # Validate (cost, accuracy) on train set\n",
    "    print(\"\\nDone with the first iterator\\n\")\n",
    "\n",
    "    sess.run(iterator5.initializer, feed_dict={filenames: validation_filenames})\n",
    "    while True:\n",
    "        try:\n",
    "            features, labels = sess.run(next_element5)\n",
    "            # Validate (cost, accuracy) on dev set\n",
    "            print(\"(dev) features: \")\n",
    "            print(features)\n",
    "            print(\"(dev) labels: \")\n",
    "            print(labels)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Out of range error triggered (looped through dev set 1 time only)\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310117b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
