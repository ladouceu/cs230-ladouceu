{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ab00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dce0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a19aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be >=2.6.2\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65928ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\"frame\":0, \"id\":1, \"x\":2, \"y\":3, \"w\":4, \"h\":5, \"x1\":6, \"x2\":7, \"conf\":9}\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be9d0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on file: data/test/MOT16-01/det/det.txt\n",
      "[[ 1.0000e+00  1.0000e+00  7.7268e+02  4.5543e+02  4.1871e+01  1.2761e+02\n",
      "   2.1262e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  2.0000e+00  7.1779e+02  4.5129e+02  4.4948e+01  1.3684e+02\n",
      "   1.7969e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  3.0000e+00  2.3074e+02  4.6507e+02  2.1974e+01  6.7922e+01\n",
      "   1.6718e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  4.0000e+00  1.0017e+03  4.5586e+02  6.3980e+01  1.9394e+02\n",
      "   6.3705e-01 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  5.0000e+00  7.0264e+02  3.7421e+02  7.3643e+01  2.2293e+02\n",
      "  -1.0042e-01 -1.0000e+00 -1.0000e+00 -1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "videos = glob.glob(\"data/test/*/det/det.txt\")\n",
    "\n",
    "for video in videos:\n",
    "    print(\"Evaluating on file: {}\".format(file))\n",
    "    data_video = np.loadtxt(file, delimiter=\",\")\n",
    "    frames = np.unique(data[:,header[\"frame\"]])\n",
    "    # put an id on all objects in the first frame\n",
    "    first_frame = min(frames)\n",
    "    data_first_frame = data_video[data_video[:,header[\"frame\"]]==first_frame,:]\n",
    "    largest_id = len(data_old_frame)\n",
    "    old_objs = # all objs from first frame in a tensor\n",
    "    old_id_map = list(range(1,largest_id+1)) # map from position in tensor above to id of object\n",
    "    data_first_frame[:,header[\"id\"]] = old_id_map\n",
    "    \n",
    "    # iterate through frames, on each next frame find the best match from\n",
    "    # the objects of the previous match and remember the matching score. \n",
    "    # The matching score must be larger than a certain threshold. Not \n",
    "    # more than 1 objects in the next frame can be matched to one object in the\n",
    "    # previous frame, so recursively go through all unmatched objects until they\n",
    "    # are all matched. If no match is found for an object, assigned a new id \n",
    "    # being largest_id + 1 \n",
    "    for frame in frames:\n",
    "        data_new_frame = data_video[data_video[:,header[\"frame\"]]==frame,:]\n",
    "        new_objs = # all objs from this new frame in a tensor\n",
    "        new_id_map = [] # map from position in tensor above to id of object\n",
    "        for r,det in enumerate(data_new_frame):\n",
    "            new_obj = # a tensor of all same pictures with same dim as old_obj\n",
    "            similarities = compute_similarity(new_obj, old_obj)\n",
    "            i = np.argmax(similarities)\n",
    "            score = similarities[i]\n",
    "            if score > thresh:\n",
    "                new_id_map += [old_id_map[i]]\n",
    "            else:\n",
    "                largest_id += 1\n",
    "                new_id_map += [largest_id]\n",
    "        \n",
    "        data_new_frame[:,header[\"id\"]] = new_id_map\n",
    "        \n",
    "        #update old variables\n",
    "        old_objs = new_objs\n",
    "        old_id_map = new_id_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "535cf51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000e+00, -1.0000e+00,  7.7268e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 1.0000e+00, -1.0000e+00,  7.1779e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 1.0000e+00, -1.0000e+00,  2.3074e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       ...,\n",
       "       [ 4.5000e+02, -1.0000e+00,  1.7248e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 4.5000e+02, -1.0000e+00,  2.8900e+02, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00],\n",
       "       [ 4.5000e+02, -1.0000e+00,  1.6055e+03, ..., -1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(files[0],delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26764f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data[0:1,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc0c4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b9020cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dbf8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "        23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "        34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "        45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "        56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "        67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "        78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "        89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "       100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "       111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "       122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "       133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "       144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154.,\n",
       "       155., 156., 157., 158., 159., 160., 161., 162., 163., 164., 165.,\n",
       "       166., 167., 168., 169., 170., 171., 172., 173., 174., 175., 176.,\n",
       "       177., 178., 179., 180., 181., 182., 183., 184., 185., 186., 187.,\n",
       "       188., 189., 190., 191., 192., 193., 194., 195., 196., 197., 198.,\n",
       "       199., 200., 201., 202., 203., 204., 205., 206., 207., 208., 209.,\n",
       "       210., 211., 212., 213., 214., 215., 216., 217., 218., 219., 220.,\n",
       "       221., 222., 223., 224., 225., 226., 227., 228., 229., 230., 231.,\n",
       "       232., 233., 234., 235., 236., 237., 238., 239., 240., 241., 242.,\n",
       "       243., 244., 245., 246., 247., 248., 249., 250., 251., 252., 253.,\n",
       "       254., 255., 256., 257., 258., 259., 260., 261., 262., 263., 264.,\n",
       "       265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
       "       276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286.,\n",
       "       287., 288., 289., 290., 291., 292., 293., 294., 295., 296., 297.,\n",
       "       298., 299., 300., 301., 302., 303., 304., 305., 306., 307., 308.,\n",
       "       309., 310., 311., 312., 313., 314., 315., 316., 317., 318., 319.,\n",
       "       320., 321., 322., 323., 324., 325., 326., 327., 328., 329., 330.,\n",
       "       331., 332., 333., 334., 335., 336., 337., 338., 339., 340., 341.,\n",
       "       342., 343., 344., 345., 346., 347., 348., 349., 350., 351., 352.,\n",
       "       353., 354., 355., 356., 357., 358., 359., 360., 361., 362., 363.,\n",
       "       364., 365., 366., 367., 368., 369., 370., 371., 372., 373., 374.,\n",
       "       375., 376., 377., 378., 379., 380., 381., 382., 383., 384., 385.,\n",
       "       386., 387., 388., 389., 390., 391., 392., 393., 394., 395., 396.,\n",
       "       397., 398., 399., 400., 401., 402., 403., 404., 405., 406., 407.,\n",
       "       408., 409., 410., 411., 412., 413., 414., 415., 416., 417., 418.,\n",
       "       419., 420., 421., 422., 423., 424., 425., 426., 427., 428., 429.,\n",
       "       430., 431., 432., 433., 434., 435., 436., 437., 438., 439., 440.,\n",
       "       441., 442., 443., 444., 445., 446., 447., 448., 449., 450.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = np.unique(data[:,header[\"frame\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470f22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b58ca7",
   "metadata": {},
   "source": [
    "# Testing my model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from siamese_model_image_location import get_siamese_model\n",
    "from train_val_gen_image_location import triplet_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56895949",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (200,200)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733c011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the train dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(triplet_gen(\"train\", batch_size, target_shape), ((tf.float32,tf.float32),(tf.float32,tf.float32),(tf.float32,tf.float32)), ((target_shape + (3,),(4,)),(target_shape + (3,),(4,)),(target_shape + (3,),(4,))))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=2^14)\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True) #TODO: should set to False?\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "# build the test dataset\n",
    "val_dataset = tf.data.Dataset.from_generator(triplet_gen(\"val\", batch_size, target_shape), ((tf.float32,tf.float32),(tf.float32,tf.float32),(tf.float32,tf.float32)), ((target_shape + (3,),(4,)),(target_shape + (3,),(4,)),(target_shape + (3,),(4,))))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=2^14)\n",
    "val_dataset = val_dataset.batch(batch_size, drop_remainder=True) #TODO: should set to False?\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7c76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build (and load if load_model_path is not None) the siamese_model\n",
    "siamese_model = get_siamese_model(target_shape, load_model_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5748a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      3/Unknown - 42s 10s/step - loss: 0.3677"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3b2241a87dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "siamese_model.fit(train_dataset, epochs=10, validation_data=val_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba2166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/siamese_network_2/model_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "siamese_model.siamese_network.save(\"models/siamese_network_2/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f75a362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "siamese_model = get_siamese_model(target_shape, load_model_path = \"models/siamese_network_2/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ec40f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([0.14314848, 0.03569299, 0.08460955, 0.40625623, 0.44383675,\n",
      "       0.07046042, 0.3818026 , 0.03915355, 0.25170058, 0.02380638,\n",
      "       0.71722186, 0.03509968, 0.12621234, 0.42653406, 0.16551697,\n",
      "       0.05132472, 0.06445332, 0.37494037, 0.07118455, 0.11165597,\n",
      "       0.07152015, 0.07872263, 0.10603108, 0.05835205, 0.10887954,\n",
      "       0.06431368, 0.35207164, 0.15309969, 0.47329527, 0.1544779 ,\n",
      "       0.10742479, 0.07486513, 0.01661921, 0.04822332, 0.5183967 ,\n",
      "       0.0760931 , 0.17659846, 0.21260379, 0.09629159, 0.05572436,\n",
      "       0.02591301, 0.1194004 , 0.58771414, 0.17668265, 0.36010253,\n",
      "       0.34608102, 0.05447887, 0.04927808, 0.5391364 , 0.3907263 ,\n",
      "       0.05363579, 0.14205173, 0.05807609, 0.01742748, 0.79502606,\n",
      "       0.02510771, 0.28954464, 0.12343122, 0.1652107 , 0.67124367,\n",
      "       0.387415  , 0.12090991, 0.00789902, 0.40083677], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([0.14624867, 0.22724676, 0.86152875, 0.16883108, 0.53843844,\n",
      "       0.11807346, 0.30635542, 0.778893  , 1.0739331 , 0.3971718 ,\n",
      "       0.62292445, 0.3188074 , 0.20215383, 0.66405845, 0.4687482 ,\n",
      "       0.07374617, 0.28686714, 3.2213295 , 0.80609137, 0.4817138 ,\n",
      "       0.22017743, 0.10969576, 1.0585306 , 0.41849473, 0.8458959 ,\n",
      "       1.0982039 , 1.4392184 , 0.53843844, 0.31490472, 0.24950553,\n",
      "       0.1355923 , 0.23720132, 0.9901613 , 0.24437706, 0.63889813,\n",
      "       0.19086632, 0.5972392 , 0.28464678, 0.18878555, 0.60551655,\n",
      "       1.7529833 , 0.13745835, 1.8883812 , 0.64266694, 1.846945  ,\n",
      "       0.36725992, 0.19619137, 0.09762646, 0.3660015 , 0.955832  ,\n",
      "       0.09762646, 0.27062425, 0.02554957, 0.57692724, 2.576479  ,\n",
      "       0.7693837 , 0.9350014 , 1.1000351 , 0.6049618 , 1.0913417 ,\n",
      "       2.0372376 , 0.9213741 , 0.18563733, 0.71818185], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "for xi in train_dataset:\n",
    "    print(siamese_model(xi))\n",
    "    break\n",
    "# get the embedding, we really want to save the embedding rather than the whole model.. and then run the test examples on the embedding (\n",
    "# the test examples are not triplets but rather just an image and a location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09350d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
